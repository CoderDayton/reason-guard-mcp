# Enhanced Chain-of-Thought MCP Server Configuration
# =================================================

# Model Configuration
models:
  # CPC encoder for compression (sentence-transformers model)
  cpc_encoder: "mistralai/Mistral-7B-Instruct-v0.2"
  # Main reasoning LLM
  reasoning_llm: "gpt-4-turbo"
  # Embedding model for semantic search
  embedding_model: "all-mpnet-base-v2"

# FAISS Configuration (Vector Search)
faiss:
  use_gpu: false  # Set true if CUDA available
  gpu_device_id: 0
  fallback_to_cpu: true
  index_type: "HNSW"
  hnsw_m: 16
  ef_construction: 200
  ef_search: 64

# Tool Configuration
tools:
  compress:
    default_ratio: 0.3
    min_sentence_length: 10
    batch_size: 32
    max_input_tokens: 50000

  mot:
    default_matrix_size: [3, 4]
    communication_pattern: "vert&hor-01"
    max_retries: 3
    timeout_seconds: 300

  long_chain:
    default_steps: 15
    verify_intermediate: true
    backtrack_on_error: true
    max_steps: 50

  verify:
    confidence_threshold: 0.7
    max_claims_per_call: 10

# LLM Configuration
llm:
  api_key_env: "OPENAI_API_KEY"
  base_url: ""  # Leave empty for default OpenAI
  timeout: 60
  retry_attempts: 3
  retry_delay: 1
  temperature: 0.7
  top_p: 0.9
  max_tokens: 2000

# Server Configuration
server:
  name: "Enhanced-CoT-MCP"
  host: "localhost"
  port: 8000
  transport: "stdio"  # stdio | http | sse

# Logging Configuration
logging:
  level: "INFO"  # DEBUG | INFO | WARNING | ERROR
  format: "json"  # json | text
  file: "logs/enhanced-cot-mcp.log"
